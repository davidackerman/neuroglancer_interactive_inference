{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/scicompsoft/home/ackermand/miniconda3/envs/neuroglancer_interactive_inference/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/groups/scicompsoft/home/ackermand/miniconda3/envs/neuroglancer_interactive_inference/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (architecture): CNNectomeUNet(\n",
       "    (unet): Sequential(\n",
       "      (0): CNNectomeUNetModule(\n",
       "        (l_conv): ModuleList(\n",
       "          (0): ConvPass(\n",
       "            (conv_pass): Sequential(\n",
       "              (0): Conv3d(1, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (1): ReLU()\n",
       "              (2): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (3): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (1): ConvPass(\n",
       "            (conv_pass): Sequential(\n",
       "              (0): Conv3d(12, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (1): ReLU()\n",
       "              (2): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (3): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (2): ConvPass(\n",
       "            (conv_pass): Sequential(\n",
       "              (0): Conv3d(72, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (1): ReLU()\n",
       "              (2): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (3): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (3): ConvPass(\n",
       "            (conv_pass): Sequential(\n",
       "              (0): Conv3d(432, 2592, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (1): ReLU()\n",
       "              (2): Conv3d(2592, 2592, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "              (3): ReLU()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (l_down): ModuleList(\n",
       "          (0): Downsample(\n",
       "            (down): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "          (1): Downsample(\n",
       "            (down): MaxPool3d(kernel_size=(3, 3, 3), stride=(3, 3, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "          (2): Downsample(\n",
       "            (down): MaxPool3d(kernel_size=(3, 3, 3), stride=(3, 3, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (r_up): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): Upsample(\n",
       "              (up): Sequential(\n",
       "                (0): Upsample(scale_factor=(2.0, 2.0, 2.0), mode=nearest)\n",
       "                (1): Conv3d(72, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (2): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (1): Upsample(\n",
       "              (up): Sequential(\n",
       "                (0): Upsample(scale_factor=(3.0, 3.0, 3.0), mode=nearest)\n",
       "                (1): Conv3d(432, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (2): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (2): Upsample(\n",
       "              (up): Sequential(\n",
       "                (0): Upsample(scale_factor=(3.0, 3.0, 3.0), mode=nearest)\n",
       "                (1): Conv3d(2592, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                (2): ReLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (r_conv): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): ConvPass(\n",
       "              (conv_pass): Sequential(\n",
       "                (0): Conv3d(84, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (1): ConvPass(\n",
       "              (conv_pass): Sequential(\n",
       "                (0): Conv3d(144, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (2): ConvPass(\n",
       "              (conv_pass): Sequential(\n",
       "                (0): Conv3d(864, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): ReLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Upsample(\n",
       "        (up): Sequential(\n",
       "          (0): Upsample(scale_factor=(2.0, 2.0, 2.0), mode=nearest)\n",
       "          (1): Conv3d(72, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (2): ConvPass(\n",
       "        (conv_pass): Sequential(\n",
       "          (0): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prediction_head): Conv3d(72, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (chain): Sequential(\n",
       "    (0): CNNectomeUNet(\n",
       "      (unet): Sequential(\n",
       "        (0): CNNectomeUNetModule(\n",
       "          (l_conv): ModuleList(\n",
       "            (0): ConvPass(\n",
       "              (conv_pass): Sequential(\n",
       "                (0): Conv3d(1, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(12, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (1): ConvPass(\n",
       "              (conv_pass): Sequential(\n",
       "                (0): Conv3d(12, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (2): ConvPass(\n",
       "              (conv_pass): Sequential(\n",
       "                (0): Conv3d(72, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (3): ConvPass(\n",
       "              (conv_pass): Sequential(\n",
       "                (0): Conv3d(432, 2592, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (1): ReLU()\n",
       "                (2): Conv3d(2592, 2592, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                (3): ReLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (l_down): ModuleList(\n",
       "            (0): Downsample(\n",
       "              (down): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "            )\n",
       "            (1): Downsample(\n",
       "              (down): MaxPool3d(kernel_size=(3, 3, 3), stride=(3, 3, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "            )\n",
       "            (2): Downsample(\n",
       "              (down): MaxPool3d(kernel_size=(3, 3, 3), stride=(3, 3, 3), padding=0, dilation=1, ceil_mode=False)\n",
       "            )\n",
       "          )\n",
       "          (r_up): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): Upsample(\n",
       "                (up): Sequential(\n",
       "                  (0): Upsample(scale_factor=(2.0, 2.0, 2.0), mode=nearest)\n",
       "                  (1): Conv3d(72, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                  (2): ReLU()\n",
       "                )\n",
       "              )\n",
       "              (1): Upsample(\n",
       "                (up): Sequential(\n",
       "                  (0): Upsample(scale_factor=(3.0, 3.0, 3.0), mode=nearest)\n",
       "                  (1): Conv3d(432, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                  (2): ReLU()\n",
       "                )\n",
       "              )\n",
       "              (2): Upsample(\n",
       "                (up): Sequential(\n",
       "                  (0): Upsample(scale_factor=(3.0, 3.0, 3.0), mode=nearest)\n",
       "                  (1): Conv3d(2592, 432, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "                  (2): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (r_conv): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): ConvPass(\n",
       "                (conv_pass): Sequential(\n",
       "                  (0): Conv3d(84, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                  (1): ReLU()\n",
       "                  (2): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                  (3): ReLU()\n",
       "                )\n",
       "              )\n",
       "              (1): ConvPass(\n",
       "                (conv_pass): Sequential(\n",
       "                  (0): Conv3d(144, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                  (1): ReLU()\n",
       "                  (2): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                  (3): ReLU()\n",
       "                )\n",
       "              )\n",
       "              (2): ConvPass(\n",
       "                (conv_pass): Sequential(\n",
       "                  (0): Conv3d(864, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                  (1): ReLU()\n",
       "                  (2): Conv3d(432, 432, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "                  (3): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): Upsample(\n",
       "          (up): Sequential(\n",
       "            (0): Upsample(scale_factor=(2.0, 2.0, 2.0), mode=nearest)\n",
       "            (1): Conv3d(72, 72, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            (2): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (2): ConvPass(\n",
       "          (conv_pass): Sequential(\n",
       "            (0): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "            (1): ReLU()\n",
       "            (2): Conv3d(72, 72, kernel_size=(3, 3, 3), stride=(1, 1, 1))\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Conv3d(72, 14, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from funlib.geometry import Coordinate\n",
    "from dacapo.experiments.architectures import CNNectomeUNetConfig\n",
    "from dacapo.experiments.tasks.distance_task_config import DistanceTaskConfig\n",
    "\n",
    "import torch\n",
    "\n",
    "input_voxel_size = (16, 16, 16)\n",
    "output_voxel_size = (8, 8, 8)\n",
    "\n",
    "channels = [\n",
    "    \"ecs\",  # extra cellular space\n",
    "    \"plasma_membrane\",\n",
    "    \"mito\",\n",
    "    \"mito_membrane\",\n",
    "    \"vesicle\",\n",
    "    \"vesicle_membrane\",\n",
    "    \"mvb\",  # endosomes\n",
    "    \"mvb_membrane\",\n",
    "    \"er\",\n",
    "    \"er_membrane\",\n",
    "    \"eres\",\n",
    "    \"nucleus\",\n",
    "    \"microtubules\",\n",
    "    \"microtubules_out\",\n",
    "]\n",
    "\n",
    "architecture_config = CNNectomeUNetConfig(\n",
    "    name=\"CellMapArchitecture\",\n",
    "    input_shape=Coordinate(\n",
    "        216, 216, 216\n",
    "    ),  # can be changed\n",
    "    eval_shape_increase=Coordinate(\n",
    "        72, 72, 72\n",
    "    ),  # can be changed\n",
    "    fmaps_in=1,\n",
    "    num_fmaps=12,\n",
    "    fmaps_out=72,\n",
    "    fmap_inc_factor=6,\n",
    "    downsample_factors=[(2, 2, 2), (3, 3, 3), (3, 3, 3)],\n",
    "    constant_upsample=True,\n",
    "    upsample_factors=[(2, 2, 2)],\n",
    ")\n",
    "\n",
    "task_config = DistanceTaskConfig(\n",
    "    name=\"DistancePrediction\",\n",
    "    # important\n",
    "    channels=channels,\n",
    "    scale_factor=50,  # target = tanh(distance / scale)\n",
    "    # training\n",
    "    mask_distances=True,\n",
    "    # evaluation\n",
    "    clip_distance=50,\n",
    "    tol_distance=10,\n",
    ")\n",
    "\n",
    "# create backbone from config\n",
    "architecture = architecture_config.architecture_type(architecture_config)\n",
    "\n",
    "# initialize task from config\n",
    "task = task_config.task_type(task_config)\n",
    "\n",
    "# adding final layers/activations to create the model\n",
    "model = task.create_model(architecture)\n",
    "\n",
    "\n",
    "path_to_weights = \"/nrs/cellmap/pattonw/crop_num_experiment/scratch_distances_many_all_many_8nm_upsample-unet_default__2/checkpoints/mito__f1_score\"\n",
    "weights = torch.load(path_to_weights, map_location=\"cuda\")\n",
    "model.load_state_dict(weights[\"model\"])\n",
    "model.to(\"cuda\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://10.150.100.248:42109/v/52c8e71b5b19385e4263f69241e6f173f2e57b9d/\n"
     ]
    }
   ],
   "source": [
    "# taken from https://github.com/google/neuroglancer/blob/master/python/examples/interactive_inference.py\n",
    "\"\"\"Example of displaying interactive image-to-image \"inference\" results.\n",
    "shift+mousedown0 triggers the inference result to be computed for the patch\n",
    "centered around the mouse position, and then displayed in neuroglancer.\n",
    "In this example, the inference result is actually just a distance transform\n",
    "computed from the ground truth segmentation, but in actual use the inference\n",
    "result may be computed using SciPy, Tensorflow, PyTorch, etc.\n",
    "The cloudvolume library (https://github.com/seung-lab/cloud-volume) is used to\n",
    "retrieve patches of the ground truth volume.\n",
    "The zarr library is used to represent the sparse in-memory array containing the\n",
    "computed inference results that are displayed in neuroglancer.\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "import neuroglancer\n",
    "import neuroglancer.cli\n",
    "import cloudvolume\n",
    "import zarr\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import tensorstore as ts\n",
    "import socket\n",
    "\n",
    "\n",
    "class InteractiveInference(object):\n",
    "    def __init__(self):\n",
    "        neuroglancer.set_server_bind_address(\n",
    "            bind_address=socket.gethostbyname(socket.gethostname())\n",
    "        )\n",
    "        viewer = self.viewer = neuroglancer.Viewer()\n",
    "        viewer.actions.add(\"inference\", self._do_inference)\n",
    "\n",
    "        # self.raw_data = ts.open({\n",
    "        # 'driver':   \n",
    "        #          'n5',\n",
    "        # 'kvstore':{\n",
    "        #     'driver': 'http',\n",
    "        #     'base_url': 'https://janelia-cosem-datasets.s3.amazonaws.com/jrc_mus-liver/jrc_mus-liver.n5/em/fibsem-uint8/s1',\n",
    "        #    }}).result()\n",
    "        group = zarr.open(zarr.N5FSStore('s3://janelia-cosem-datasets/jrc_mus-liver/jrc_mus-liver.n5/', anon=True)) # access the root of the n5 container\n",
    "        self.raw_s1 = group['em/fibsem-uint8/s1'] # s0 is the the full-resolution data for this particular volume\n",
    "        self.raw_s0 = group['em/fibsem-uint8/s0'] # s0 is the the full-resolution data for this particular volume\n",
    "        # Create a 3-d view (remove singleton 'channel' dimension):\n",
    "\n",
    "        self.dimensions = neuroglancer.CoordinateSpace(\n",
    "                     names=[\"x\", \"y\", \"z\"],\n",
    "                     units=\"nm\",\n",
    "                     scales=self.raw_s0.attrs['transform']['scale'][::-1],\n",
    "        )\n",
    "\n",
    "\n",
    "        with viewer.config_state.txn() as s:\n",
    "            s.input_event_bindings.data_view[\"shift+mousedown0\"] = \"inference\"\n",
    "\n",
    "        with viewer.txn() as s:\n",
    "            s.layers[\"raw\"] = neuroglancer.ImageLayer(\n",
    "                source=\"n5://s3://janelia-cosem-datasets/jrc_mus-liver/jrc_mus-liver.n5/em/fibsem-uint8\",\n",
    "                shader=\"\"\"#uicontrol invlerp normalized(range=[105, 182], window=[0, 255])\\n\n",
    "                #uicontrol int invertColormap slider(min=0, max=1, step=1, default=0)\\n\n",
    "        #uicontrol vec3 color color(default=\"white\")\n",
    "        float inverter(float val, int invert) {return 0.5 + ((2.0 * (-float(invert) + 0.5)) * (val - 0.5));}\\n\n",
    "          void main() {\\n\n",
    "          emitRGB(color * inverter(normalized(), invertColormap));\n",
    "        }\"\"\"\n",
    "            )\n",
    "        \n",
    "            self.inf_results = []\n",
    "            self.inf_volumes = []\n",
    "            for organelle in channels:\n",
    "                self.inf_results.append( zarr.zeros(\n",
    "                    self.raw_s0.shape[::-1], chunks=(64, 64, 64), dtype=np.uint8\n",
    "                ))\n",
    "                self.inf_volumes.append(neuroglancer.LocalVolume(\n",
    "                    data=self.inf_results[-1], dimensions=self.dimensions\n",
    "                ))\n",
    "                s.layers[organelle] = neuroglancer.ImageLayer(source=self.inf_volumes[-1],\n",
    "                    shader=\"#uicontrol invlerp normalized \\nvoid main() {\\n\\temitRGB(vec3(normalized(),0, 0));\\n}\",\n",
    "                    shaderControls = {\n",
    "                            \"normalized\": {\"range\": [127, 127]}\n",
    "                        },\n",
    "                )\n",
    "                s.layers[organelle].visible = organelle==\"mito\"\n",
    "    #             s.layers[\"ground_truth\"] = neuroglancer.SegmentationLayer(\n",
    "    #                 source=\"precomputed://gs://neuroglancer-public-data/flyem_fib-25/ground_truth\",\n",
    "    #             )\n",
    "    #             s.layers[\"ground_truth\"].visible = False\n",
    "    #             s.layers[\"inference\"] = neuroglancer.ImageLayer(\n",
    "    #                 source=self.inf_volume,\n",
    "    #                 shader=\"\"\"\n",
    "    # void main() {\n",
    "    #   float v = toNormalized(getDataValue(0));\n",
    "    #   vec4 rgba = vec4(0,0,0,0);\n",
    "    #   if (v != 0.0) {\n",
    "    #     rgba = vec4(colormapJet(v), 1.0);\n",
    "    #   }\n",
    "    #   emitRGBA(rgba);\n",
    "    # }\n",
    "    # \"\"\",\n",
    "    #             )\n",
    "\n",
    "    def _do_inference(self, action_state):\n",
    "        s0_pos = action_state.mouse_voxel_coordinates\n",
    "        if s0_pos is None:\n",
    "            return\n",
    "\n",
    "        s1_pos = s0_pos[::-1]//2\n",
    "        patch_size = np.array((216,) * 3, np.int64)\n",
    "        spos = s1_pos - patch_size //2\n",
    "        epos = spos + patch_size\n",
    "        slice_expr = np.s_[\n",
    "            int(spos[0]) : int(epos[0]),\n",
    "            int(spos[1]) : int(epos[1]),\n",
    "            int(spos[2]) : int(epos[2]),\n",
    "        ]\n",
    "\n",
    "        raw_s1 = self.raw_s1[slice_expr]/255.0\n",
    "        raw_s1 = np.reshape(raw_s1, (1,1,216,216,216))\n",
    "        outputs = model(torch.from_numpy(raw_s1).float().to(\"cuda\"))\n",
    "        outputs = (outputs.cpu().detach().numpy())\n",
    "        outputs[outputs<-1] = -1\n",
    "        outputs[outputs>1] = 1\n",
    "        outputs = outputs*127.5+127.5\n",
    "        patch_size = np.array((68,)*3, np.int64)\n",
    "\n",
    "        spos = s0_pos - patch_size //2\n",
    "        epos = spos + patch_size\n",
    "        slice_expr = np.s_[\n",
    "            int(spos[0]) : int(epos[0]),\n",
    "            int(spos[1]) : int(epos[1]),\n",
    "            int(spos[2]) : int(epos[2]),\n",
    "        ]\n",
    "        patch_size = np.array((68,) * 3, np.int64)\n",
    "        \n",
    "        for i,channel in enumerate(channels):\n",
    "            self.inf_results[i][slice_expr] = np.transpose(outputs[0][i].astype(np.uint8))\n",
    "            self.inf_volumes[i].invalidate()\n",
    "\n",
    "inf = InteractiveInference()\n",
    "print(inf.viewer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:12:21,359 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-xjn5s12d', purging\n",
      "2022-10-25 00:12:21,366 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-lf9j1iij', purging\n",
      "2022-10-25 00:12:21,373 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-cvp2cs47', purging\n",
      "2022-10-25 00:12:21,379 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-vufswzxt', purging\n",
      "2022-10-25 00:12:21,386 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-dg0nl5f3', purging\n",
      "2022-10-25 00:12:21,392 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-nhrhpmid', purging\n",
      "2022-10-25 00:12:21,398 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-k0n27frc', purging\n",
      "2022-10-25 00:12:21,405 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-_o1owe_v', purging\n",
      "2022-10-25 00:12:21,411 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-tjnhcobd', purging\n",
      "2022-10-25 00:12:21,417 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-s4sw1smn', purging\n",
      "2022-10-25 00:12:21,424 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-51jn2ibj', purging\n",
      "2022-10-25 00:12:21,430 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-jn3k9kxy', purging\n",
      "2022-10-25 00:12:21,436 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-kydqiw79', purging\n",
      "2022-10-25 00:12:21,442 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-1t3rjdw1', purging\n",
      "2022-10-25 00:12:21,448 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-mhvhc114', purging\n",
      "2022-10-25 00:12:21,454 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-8fdsxzrm', purging\n",
      "2022-10-25 00:12:21,459 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-25ufh456', purging\n",
      "2022-10-25 00:12:21,465 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-8xww08cg', purging\n",
      "2022-10-25 00:12:21,471 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-nl5nvymb', purging\n",
      "2022-10-25 00:12:21,477 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-mztoaf85', purging\n",
      "2022-10-25 00:12:21,483 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-q4y8rprz', purging\n",
      "2022-10-25 00:12:21,488 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-hmz2ha57', purging\n",
      "2022-10-25 00:12:21,494 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-b08ubhl8', purging\n",
      "2022-10-25 00:12:21,500 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-n5kg2e_x', purging\n",
      "2022-10-25 00:12:21,506 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-npp0_exa', purging\n",
      "2022-10-25 00:12:21,512 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-qxfuabf8', purging\n",
      "2022-10-25 00:12:21,518 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-zyibmgke', purging\n",
      "2022-10-25 00:12:21,524 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-z8ms3x0b', purging\n",
      "2022-10-25 00:12:21,529 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-x_of2l6m', purging\n",
      "2022-10-25 00:12:21,535 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-h7a2awnn', purging\n",
      "2022-10-25 00:12:21,540 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-4lpsjqpn', purging\n",
      "2022-10-25 00:12:21,546 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-l1t6d84o', purging\n",
      "2022-10-25 00:12:21,551 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-8up9dral', purging\n",
      "2022-10-25 00:12:21,557 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-zmwy1m46', purging\n",
      "2022-10-25 00:12:21,563 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-0pyho4q9', purging\n",
      "2022-10-25 00:12:21,569 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-s3pg43hg', purging\n",
      "2022-10-25 00:12:21,574 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-j8evt6yq', purging\n",
      "2022-10-25 00:12:21,580 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-6eyb0m9x', purging\n",
      "2022-10-25 00:12:21,586 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-_bxdbrbb', purging\n",
      "2022-10-25 00:12:21,592 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-lgcydk0j', purging\n",
      "2022-10-25 00:12:21,598 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-_xted8mm', purging\n",
      "2022-10-25 00:12:21,604 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-5wn0ev34', purging\n",
      "2022-10-25 00:12:21,610 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-f30g1krj', purging\n",
      "2022-10-25 00:12:21,615 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-yt5g6pww', purging\n",
      "2022-10-25 00:12:21,621 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-8aqehm3l', purging\n",
      "2022-10-25 00:12:21,627 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-21nh30ae', purging\n",
      "2022-10-25 00:12:21,632 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-s8e7osqb', purging\n",
      "2022-10-25 00:12:21,638 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-ay12fc0r', purging\n",
      "2022-10-25 00:12:21,644 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-auo6pa5v', purging\n",
      "2022-10-25 00:12:21,650 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-bsk66flg', purging\n",
      "2022-10-25 00:12:21,656 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-9_5bj17h', purging\n",
      "2022-10-25 00:12:21,662 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-yiyb4ej4', purging\n",
      "2022-10-25 00:12:21,668 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-6cawkm_3', purging\n",
      "2022-10-25 00:12:21,673 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-o4h0todm', purging\n",
      "2022-10-25 00:12:21,679 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-clbjko_i', purging\n",
      "2022-10-25 00:12:21,685 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-xshmo8hy', purging\n",
      "2022-10-25 00:12:21,690 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-pm8sn2ht', purging\n",
      "2022-10-25 00:12:21,696 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-f6fof02f', purging\n",
      "2022-10-25 00:12:21,701 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-_ep07122', purging\n",
      "2022-10-25 00:12:21,707 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-wr00zfp8', purging\n",
      "2022-10-25 00:12:21,713 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-j5sgnk7s', purging\n",
      "2022-10-25 00:12:21,718 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-ncnh2fqd', purging\n",
      "2022-10-25 00:12:21,723 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-v4z5ep4w', purging\n",
      "2022-10-25 00:12:21,729 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-putqf1bu', purging\n",
      "2022-10-25 00:12:21,735 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-z9gbc6wi', purging\n",
      "2022-10-25 00:12:21,741 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-ck9s2lh5', purging\n",
      "2022-10-25 00:12:21,746 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-3uflq7be', purging\n",
      "2022-10-25 00:12:21,752 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-dgjy4aoq', purging\n",
      "2022-10-25 00:12:21,758 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-ice0rto_', purging\n",
      "2022-10-25 00:12:21,764 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-unqokheg', purging\n",
      "2022-10-25 00:12:21,769 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-el__wlaz', purging\n",
      "2022-10-25 00:12:21,775 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-tcwhj_7c', purging\n",
      "2022-10-25 00:12:21,780 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-9337_uqb', purging\n",
      "2022-10-25 00:12:21,786 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-nrmy3rgm', purging\n",
      "2022-10-25 00:12:21,792 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-xgn5xuxs', purging\n",
      "2022-10-25 00:12:21,798 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-gkziarzp', purging\n",
      "2022-10-25 00:12:21,804 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-dzrccba1', purging\n",
      "2022-10-25 00:12:21,810 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-h2u06299', purging\n",
      "2022-10-25 00:12:21,816 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-vaa6rxi4', purging\n",
      "2022-10-25 00:12:21,822 - distributed.diskutils - INFO - Found stale lock file and directory '/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/dask-worker-space/worker-5ag04s_r', purging\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://10.150.100.248:8787/status\n",
      "0\n",
      "272\n",
      "544\n",
      "816\n",
      "1088\n",
      "1360\n",
      "1632\n",
      "1904\n",
      "2176\n",
      "2448\n",
      "2720\n",
      "2992\n",
      "3264\n",
      "3536\n",
      "3808\n",
      "4080\n",
      "4352\n",
      "4624\n",
      "4896\n",
      "5168\n",
      "5440\n",
      "5712\n",
      "5984\n",
      "6256\n",
      "6528\n",
      "6800\n",
      "7072\n",
      "7344\n",
      "7616\n",
      "7888\n",
      "8160\n",
      "8432\n",
      "8704\n",
      "8976\n",
      "9248\n",
      "9520\n",
      "9792\n",
      "10064\n",
      "10336\n",
      "10608\n",
      "10880\n",
      "11152\n",
      "11424\n",
      "11696\n",
      "11968\n",
      "12240\n",
      "12512\n",
      "http://10.150.100.248:34087/v/d93acb89a122eed1a427131c2f54de6c401ec975/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36448\n",
      "Computing k=36449Computing k=36447\n",
      "\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36449\n",
      "Computing k=36449\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36449\n",
      "Computing k=36448\n",
      "Computing k=36447\n",
      "Computing k=36449\n",
      "Computing k=36448\n",
      "Computing k=36447\n",
      "Computing k=36449\n",
      "Computing k=36447\n",
      "Computing k=36449\n",
      "Computing k=36447\n",
      "Computing k=36447\n",
      "Computing k=36447\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448Computing k=36448\n",
      "\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36449\n",
      "Computing k=36448Computing k=36448\n",
      "\n",
      "Computing k=36449Computing k=36449\n",
      "\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36449\n",
      "Computing k=36449Computing k=36448\n",
      "Computing k=36448\n",
      "\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448\n",
      "Computing k=36448Computing k=36448\n",
      "Computing k=36449\n",
      "\n",
      "Computing k=36448Computing k=36448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:17:23,171 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:17:26,838 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36448Computing k=36448\n",
      "\n",
      "Computing k=36449\n",
      "Computing k=36449Computing k=36447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:17:31,093 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:17:32,283 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:17:36,758 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:17:39,888 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:17:42,933 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:17:47,874 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36449\n",
      "Computing k=36447Computing k=36447\n",
      "\n",
      "Computing k=36449\n",
      "Computing k=36447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:17:51,645 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:17:52,784 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:17:58,145 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:00,214 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:04,336 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:06,278 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36449Computing k=36449\n",
      "\n",
      "Computing k=36447\n",
      "Computing k=36449Computing k=36447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:18:11,817 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:13,860 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:18,611 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:20,573 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:24,181 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:27,640 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36449Computing k=36449\n",
      "\n",
      "Computing k=36447\n",
      "Computing k=36447\n",
      "Computing k=36449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:18:31,844 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:34,397 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:38,648 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:41,765 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:44,742 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:47,684 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36447\n",
      "Computing k=36447\n",
      "Computing k=36449Computing k=36447\n",
      "\n",
      "Computing k=36449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:18:53,346 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:55,770 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:18:59,892 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:02,428 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:07,220 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36449\n",
      "Computing k=36449\n",
      "Computing k=36447\n",
      "Computing k=36447\n",
      "Computing k=36449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:19:13,047 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:18,060 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:20,549 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:24,379 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:27,511 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36449Computing k=36447Computing k=36449\n",
      "\n",
      "Computing k=36447\n",
      "\n",
      "Computing k=36447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:19:32,487 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:35,573 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:37,952 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:43,003 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:44,989 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:48,225 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36449Computing k=36447Computing k=36447\n",
      "\n",
      "\n",
      "Computing k=36449\n",
      "Computing k=36447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:19:53,621 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:56,377 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:19:58,900 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:20:04,296 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:20:07,568 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36447\n",
      "Computing k=36449Computing k=36449\n",
      "\n",
      "Computing k=36447\n",
      "Computing k=36449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:20:11,815 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:20:14,216 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:20:18,562 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:20:21,257 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:20:25,069 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36447Computing k=36447\n",
      "\n",
      "Computing k=36447Computing k=36447\n",
      "Computing k=36447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:20:29,951 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:20:32,025 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:20:34,105 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36447\n",
      "Computing k=36447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:25:08,378 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:26:30,622 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:26:32,758 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:26:38,204 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:26:41,863 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:26:49,459 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:26:53,623 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:26:58,694 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:02,131 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36445\n",
      "Computing k=36447\n",
      "Computing k=36446\n",
      "Computing k=36448\n",
      "Computing k=36449Computing k=36447\n",
      "\n",
      "Computing k=36446Computing k=36446\n",
      "\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:27:05,237 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:07,491 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:10,682 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:12,301 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:27:18,353 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:19,579 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:21,857 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:26,389 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:29,652 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:33,480 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36446\n",
      "Computing k=36445\n",
      "Computing k=36445Computing k=36445\n",
      "\n",
      "Computing k=36445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:27:38,255 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:40,140 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:44,222 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:48,613 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:51,854 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:27:54,111 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36446Computing k=36445\n",
      "\n",
      "Computing k=36444Computing k=36445\n",
      "\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:27:59,062 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:01,244 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:04,804 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:07,953 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:10,780 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36446Computing k=36446\n",
      "\n",
      "Computing k=36446\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:28:14,683 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:17,342 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:20,440 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:23,223 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:27,951 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:30,455 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36446Computing k=36446\n",
      "\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:28:36,447 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:37,779 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:42,541 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:44,772 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:28:49,643 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446Computing k=36446\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:28:56,875 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:00,750 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:03,517 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:07,767 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:10,389 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:29:15,955 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:17,996 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:23,369 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:28,399 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:32,070 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:29:35,423 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:38,236 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:42,542 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:46,682 - distributed.utils_perf - WARNING - full garbage collections took 28% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:48,283 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:52,674 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:29:55,706 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:29:58,174 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:02,427 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:05,314 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:09,365 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36445\n",
      "Computing k=36445Computing k=36445\n",
      "\n",
      "Computing k=36445Computing k=36445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:30:15,561 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:17,829 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:22,686 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:26,113 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:28,416 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36443\n",
      "Computing k=36442\n",
      "Computing k=36440\n",
      "Computing k=36441\n",
      "Computing k=36445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:30:33,642 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:35,580 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:40,087 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:42,893 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:47,188 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:50,775 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36444\n",
      "Computing k=36444\n",
      "Computing k=36444Computing k=36444\n",
      "\n",
      "Computing k=36444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:30:54,896 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:30:57,182 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:02,767 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:05,557 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:09,567 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36444\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:31:14,243 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:16,188 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:21,999 - distributed.utils_perf - WARNING - full garbage collections took 27% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:25,596 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:28,713 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:31:34,119 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:36,002 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:41,013 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:43,653 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:47,315 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:50,947 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:31:55,930 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:31:58,881 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:01,870 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:06,963 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:09,324 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36447\n",
      "Computing k=36446\n",
      "Computing k=36447\n",
      "Computing k=36447\n",
      "Computing k=36450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:32:14,821 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:16,595 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:21,406 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:23,860 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:29,329 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:32:35,754 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:37,754 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:42,233 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:44,668 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:51,006 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36446\n",
      "Computing k=36447\n",
      "Computing k=36447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:32:55,968 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:32:57,782 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:33:01,836 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:33:05,017 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:33:07,672 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36445\n",
      "Computing k=36445\n",
      "Computing k=36447Computing k=36445\n",
      "\n",
      "Computing k=36445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-25 00:33:14,414 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:33:16,047 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:33:20,458 - distributed.utils_perf - WARNING - full garbage collections took 26% CPU time recently (threshold: 10%)\n",
      "2022-10-25 00:33:25,800 - distributed.utils_perf - WARNING - full garbage collections took 25% CPU time recently (threshold: 10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing k=36445Computing k=36445\n",
      "Computing k=36445\n",
      "\n",
      "Computing k=36445\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import neuroglancer\n",
    "import numpy as np\n",
    "import zarr\n",
    "import socket\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(threads_per_worker=2, n_workers=1)\n",
    "client.cluster.scale(20)\n",
    "dashboard_link = client.cluster.dashboard_link\n",
    "print(dashboard_link.replace(\"127.0.0.1\",socket.gethostbyname(socket.gethostname())))\n",
    "\n",
    "def add_dask_layer(state):\n",
    "    \"\"\"Adds a lazily-computed data source backed by dask.\"\"\"\n",
    "    # https://docs.dask.org/en/latest/array-creation.html#using-dask-delayed\n",
    "    import dask\n",
    "    import dask.array\n",
    "\n",
    "    def make_array(k):\n",
    "        print(\"Computing k=%d\" % (k,))\n",
    "        return np.random.randint(low=0, high=255, size=(256, 256, 256), dtype=np.uint8)\n",
    "\n",
    "    x_max = 12747\n",
    "    y_max = 12728\n",
    "    z_max = 8932\n",
    "    lazy_make_array = dask.delayed(make_array, pure=True)\n",
    "    count = 0\n",
    "    shape = 68*4\n",
    "    arrays = [None]*((int(np.ceil(x_max/shape))+1) * (int(np.ceil(y_max/shape))+1) * (int(np.ceil(z_max/shape))+1))\n",
    "    for x in range(0,x_max,shape):\n",
    "        print(x)\n",
    "        for y in range(0,y_max,shape):\n",
    "            for z in range(0,z_max,shape):\n",
    "                arrays[count]= dask.array.from_delayed(lazy_make_array(count), dtype=np.uint8, shape=(256,256,256))\n",
    "                count+=1\n",
    "    arrays[count:]=[]\n",
    "    # lazy_chunks[count:]=[]\n",
    "    # sample = lazy_chunks[\n",
    "    #     0\n",
    "    # ].compute()  # load the first chunk (assume rest are same shape/dtype)\n",
    "    # arrays = [\n",
    "    #     dask.array.from_delayed(lazy_chunk, dtype=sample.dtype, shape=sample.shape)\n",
    "    #     for lazy_chunk in lazy_chunks\n",
    "    # ]\n",
    "    group = zarr.open(zarr.N5FSStore('s3://janelia-cosem-datasets/jrc_mus-liver/jrc_mus-liver.n5/', anon=True)) # access the root of the n5 container\n",
    "    raw_s1 = group['em/fibsem-uint8/s1'] # s0 is the the full-resolution data for this particular volume\n",
    "    x = dask.array.concatenate(arrays)\n",
    "    state.layers[\"dask\"] = neuroglancer.ImageLayer(source = neuroglancer.LocalVolume(x))#dask.array.from_array(raw_s1, chunks=(64,64,64))))\n",
    "\n",
    "neuroglancer.set_server_bind_address(\n",
    "    bind_address=socket.gethostbyname(socket.gethostname())\n",
    ")\n",
    "viewer = neuroglancer.Viewer()\n",
    "with viewer.txn() as s:\n",
    "    add_dask_layer(s)\n",
    "print(viewer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/interactive_inference.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Backermand-ws2/groups/cellmap/cellmap/ackermand/Programming/neuroglancer_interactive_inference/interactive_inference.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m count\n",
      "\u001b[0;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('neuroglancer_interactive_inference')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ae8319857bec65f820343687ad310121b78c0a1f1388ab69ef71b3f66e804a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
